{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in d:\\software\\anaconda\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: tqdm>=2.0 in d:\\software\\anaconda\\lib\\site-packages (from sklearn_crfsuite) (4.47.0)\n",
      "Requirement already satisfied: tabulate in d:\\software\\anaconda\\lib\\site-packages (from sklearn_crfsuite) (0.8.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in d:\\software\\anaconda\\lib\\site-packages (from sklearn_crfsuite) (0.9.7)\n",
      "Requirement already satisfied: six in d:\\software\\anaconda\\lib\\site-packages (from sklearn_crfsuite) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\software\\anaconda\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: nltk in d:\\software\\anaconda\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in d:\\software\\anaconda\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in d:\\software\\anaconda\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in d:\\software\\anaconda\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in d:\\software\\anaconda\\lib\\site-packages (from nltk) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "#install required packages\n",
    "!pip install sklearn_crfsuite\n",
    "!pip install scikit-learn \n",
    "!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd \n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn_crfsuite\n",
    "\n",
    "#from matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from itertools\n",
    "from itertools import chain\n",
    "\n",
    "#from sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function turns the file into a list. \n",
    "def file2list(fileLocation):\n",
    "    outputList = []\n",
    "    with open(fileLocation, 'r', encoding='utf8') as myfile:\n",
    "        sentences = myfile.read().split('\\n\\n')\n",
    "        for sentence in sentences:\n",
    "                sentenceList = []\n",
    "                words = sentence.split('\\n')\n",
    "                for word in words:\n",
    "                    wordsList = []\n",
    "                    attributes = word.split(' ')\n",
    "                    for attribute in attributes:\n",
    "                        wordsList.append(attribute)\n",
    "                    sentenceList.append(wordsList)\n",
    "                outputList.append(sentenceList)\n",
    "    \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train =  file2list('D:\\\\phd-data\\\\NER-annotation-data\\\\Dutch\\\\5-folds-with-pos-with-cut-sentences\\\\fold1.txt') \n",
    "# test =  file2list('D:\\\\phd-data\\\\NER-annotation-data\\\\Dutch\\\\5-folds-with-pos-with-cut-sentences\\\\fold2.txt')\n",
    "\n",
    "#load the datasets, with training documents as train, and test documents and test\n",
    "train =  file2list('txt/train.txt') \n",
    "test =  file2list('txt/test.txt') \n",
    "#remove empty lines as this breaks the code\n",
    "test.pop() \n",
    "train.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['INTRODUCTION', 'NNP', 'O'],\n",
       " ['7', 'CD', 'O'],\n",
       " ['1.1', 'CD', 'O'],\n",
       " ['Project', 'NN', 'O'],\n",
       " ['Background', 'NNP', 'O'],\n",
       " ['7', 'CD', 'O'],\n",
       " ['1.2', 'CD', 'O'],\n",
       " ['Site', 'NNP', 'O'],\n",
       " ['Location', 'NNP', 'O'],\n",
       " ['and', 'CC', 'O'],\n",
       " ['Description', 'NNP', 'O'],\n",
       " ['7', 'CD', 'O'],\n",
       " ['1.3', 'CD', 'O'],\n",
       " ['Archaeological', 'NNP', 'O'],\n",
       " ['Background', 'NNP', 'O'],\n",
       " ['7', 'CD', 'O'],\n",
       " ['1.4', 'CD', 'O'],\n",
       " ['Methodologies', 'NNS', 'O'],\n",
       " ['9', 'CD', 'O'],\n",
       " ['1.5', 'CD', 'O'],\n",
       " ['Professional', 'JJ', 'O'],\n",
       " ['Standards', 'NNS', 'O'],\n",
       " ['9', 'CD', 'O'],\n",
       " ['2', 'CD', 'O'],\n",
       " ['.', '.', 'O']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# calculates the time to open the file\n",
    "        #train the NER on the list. there is one set of test and one of training. often 20:80 split\n",
    "train_sent = train\n",
    "test_sent = test   # tests the sent (input) of the given list as defined above\n",
    "train_sent[0] # displayes the first 10 rows in the bio. - each row hs the token (effectively word), followed by pos?, and the bio label\n",
    "# to identify whats below - token - label(specific label) - common derivitive of word (for posting would be post)  - then the bio label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elm', 'felt', 'alabaster', 'spruce', 'tamarac', 'aluminum', 'variscite', 'argillite', 'totternhoe clunch', 'ash', 'aluminium', 'carnelian', 'cornelian', 'plaster', 'sapphire', 'paper', 'ebony', 'garnet', 'rubber', 'coal', 'emerald', 'hazel', 'puddingstone', 'hertfordshire puddingstone', 'charcoal', 'chalk', 'hydrocarbon', 'bakelite', 'amethyst', 'amphibolite', 'larch', 'siltstone', 'mudstone', 'utahlite', 'teak', 'shale', 'ivory', 'marble', 'limestone', 'leather', 'lead', 'lava', 'faience', 'jadeite', 'tooth', 'iron', 'pottery', 'greenstone', 'gold', 'glass', 'flint', 'jet', 'silver', 'pewter', 'obsidian', 'sandstone', 'object material', 'oak', 'mineral', 'wood', 'shell', 'quartz', 'slate', 'steel', 'stone', 'terracotta', 'tin', 'granite', 'quartzite', 'fir', 'antimony', 'schist', 'birch', 'lead alloy', 'zinc', 'dolerite', 'ceramic', 'pine', 'fibreglass', 'glass fibre', 'graphite', 'jade', 'onyx', 'fiberglass', 'beech', 'textile', 'metal', 'alloy', 'bronze', 'horn', 'brass', 'bone', 'antler', 'animal', 'cement', 'chert', 'clay', 'concrete', 'copper', 'amber', 'copper alloy', 'enamel', 'earthenware']\n",
      "\n",
      "\n",
      "\n",
      "['ヒメシンサンカクガイ', 'australmuschel australian', 'brooch clam', 'große flussperlmuschel', 'riesen-flussperlmuschel', \"spengler's freshwater mussel\", 'giant european freshwater pearl mussel', 'louisiana pearlshell', 'western pearlshell', 'westliche flussperlmuschel', 'western freshwater pearl mussel', 'alabama pearlshell', 'eastern pearlshell', 'flussperlmuschel', 'scottish pearl mussel', 'freshwater pearl mussel', 'ウスモシオ', 'スダレモシオ', 'モシオガイ', 'ワタゾコモシオ', 'サガミモシオガイ', 'zwinkokkel', 'フミガイ', 'ハタウネフミガイ', 'rudder cardita', 'トマヤガイ', 'ニクイロトマヤガイ', 'rectangular false cockle', 'クロフトマヤガイ', 'large-ribbed cardita', 'クロマルフミガイ', 'vénéricarde boréale', 'new england cyclocardia', 'north pacific bobtail squid', 'north pacific bobtail squid', 'bouzuika', 'globito del pacífico boreal', 'sépiole du pacifique boréal', 'globito de tasmania', 'sarura', 'southern bobtail squid', 'sépiole du tasmanie', 'mimika bobtail', 'mimika bobtail squid', 'mò-shì-sì-pán-êr-wu-zéi', 'globito mimika', 'sépiole mimika', 'ミミイカ', 'bèi-ruì-shì-sì-pán-êr-wu-zéi', 'double-ear bobtail', 'globito colibri', 'humming-bird bobtail squid', 'leung yee jai', 'niyori-mimi-ika', 'sépiole colibri', 'ニヨリミミイカ', 'brenner’s bobtail', 'burenā-mimika', 'rì-bĕn-àn-êr-wu-zéi', 'チョウチンイカ', 'kleine sepiette', 'linsen-sepiette', 'cappuccetto', 'globito pequeño', 'lentil bobtail', 'lentil bobtail squid', 'seppiola minore', 'sépiole bobie', 'σουπίτσα', 'σουπίτσα φακή', 'elegante sepiette', 'elegant bobtail', 'elegant bobtail squid', 'sepieta elegante', 'sépiole élégante', 'συμμετρική σουπίτσα', 'obskure sepiette', 'sepiette', 'mysterious bobtail squid', 'ramshorn', 'sepieta misteriosa', 'seppiola misteriosa', 'sépiole mystérieuse', 'σουπίτσα αίνιγμα', 'große sepiette', 'cappuccetto', 'common bobtail', 'common bobtail squid', 'greater cuttlefish', 'langwerpige dwerginktvis', 'sepieta común', 'seppiola comune', 'supion', 'sépiole', 'sépiole commune', 'σουπίτσα', 'atlantic bobtail', 'atlantic bobtail squid', 'atlantic cuttlefish', 'atlantik-stummelschwanzsepi']\n",
      "\n",
      "\n",
      "\n",
      "['la tène c', 'la tène d', 'la tène d1', 'la tène d2', 'silla kingdom', 'koguryo kingdom', 'paekche kingdom', 'sasanian', 'unified silla dynasty', 'kushano-sasanian', 'western turks', 'alchon', 'indo-greek', 'hun', 'greco-bactrian', 'epi-palaeolithic', 'hephthalite', 'tularosa', 'afsharid dynasty', 'old assyrian', 'late babylonian', 'neo-babylonian dynasty', 'dilmun', 'punuk', 'old bering sea culture', 'inca', 'late bronze age/early iron age', 'romano-british', 'early medieval', 'pagan', 'sonso', 'gaudo', 'early archaic', 'middle archaic', 'punic', 'kushan', 'bmac', 'rimac', 'calima', 'san agustin', 'tumaco', 'tumaco-la tolita', 'early quimbaya', 'quimbaya', 'yotoco', 'zenu', 'early tolima', 'san agustin regional classic', 'tolima', 'tairona', 'muisca', 'narino', 'late quimbaya', 'serrania de san jacinto', 'tairona period', 'cauca', 'proto-corinthian', 'early minoan', 'early minoan i', 'early minoan ii', 'early minoan iia', 'early minoan iib', 'early minoan iii', 'middle minoan', 'middle minoan i', 'middle minoan ia', 'middle minoan ib', 'middle minoan ii', 'middle minoan iia', 'middle minoan iib', 'middle minoan iii', 'middle minoan iiia', 'middle minoan iiib', 'late minoan', 'late minoan i', 'late minoan ia', 'late minoan ib', 'late minoan ii', 'late minoan iii', 'late minoan iiia', 'late minoan iiia1', 'late minoan iiia2', 'late minoan iiib', 'late minoan iiib1', 'late minoan iiib2', 'late minoan iiic', 'sub-minoan', 'early cycladic', 'grotta-pelos culture', 'keros-syros culture', 'phylakopi i culture', 'middle cycladic', 'late cycladic', 'early cypriot', 'early cypriot i', 'early cypriot ii', 'early cypriot iii', 'middle cypriot', 'late cypriot', 'late cypriot ib']\n",
      "\n",
      "\n",
      "\n",
      "['post-hole', 'post-hole', 'post-hole', 'post-hole', 'post-hole', 'building', 'building', 'building', 'building', 'building', 'building', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'drain', 'drain', 'drain', 'drain', 'drain', 'drain', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'hearth', 'hearth', 'hearth', 'hearth', 'hearth', 'hearth', 'kiln', 'kiln', 'kiln', 'kiln', 'kiln', 'kiln', 'oven', 'oven', 'oven', 'oven', 'oven', 'oven', 'road', 'road', 'road', 'road', 'road', 'road', 'structure', 'structure', 'structure', 'structure', 'structure', 'structure', 'well', 'well', 'well', 'well', 'well', 'well', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'bank', 'bank', 'bank', 'bank', 'bank']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#time to load the ontologies \n",
    "\n",
    "#Material ontology\n",
    "materials = pd.read_csv(r'ontologies\\Materials.csv') #open the file\n",
    "materials[materials.columns[2]]= materials[materials.columns[2]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "materials_list = materials[materials.columns[2]].values.tolist() #turns the items into a list\n",
    "print(materials_list) # outputs the list of terms to see what sort of data it contains\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "#Taxon ontology\n",
    "# taxon = pd.read_csv(r'ontologies\\Taxon.tsv', sep=\"\\t\", error_bad_lines=False) #open the file\n",
    "# taxon[taxon.columns[8]]= taxon[taxon.columns[8]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "# taxon_list = taxon[taxon.columns[8]].values.tolist() #turns the items into a list\n",
    "# print(taxon_list[0:100]) # outputs the list of terms to see what sort of data it contains\n",
    "# print(\"\\n\"\"\\n\")\n",
    "\n",
    "#Animal ontology\n",
    "animal = pd.read_csv(r'ontologies\\VernacularName.tsv', sep=\"\\t\") #open the file\n",
    "animal[animal.columns[2]]= animal[animal.columns[2]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "animal_list = animal[animal.columns[2]].values.tolist() #turns the items into a list\n",
    "print(animal_list[0:100]) # outputs the list of terms to see what sort of data it contains\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "\n",
    "#Periods ontology - for notes see above\n",
    "periods = pd.read_csv(r'ontologies\\Periods.csv')\n",
    "periods[periods.columns[1]]= periods[periods.columns[1]].str.lower()\n",
    "periods_list = periods[periods.columns[1]].values.tolist()\n",
    "print(periods_list[0:100])\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "\n",
    "#Context ontology - for notes see material \n",
    "context = pd.read_csv(r'ontologies\\context.csv')\n",
    "context[context.columns[0]]= context[context.columns[0]].str.lower().str.replace('*','').str.replace('<','').str.replace('>','') #replace all other symbols\n",
    "context[context.columns[0]]= context[context.columns[0]].replace(to_replace =':.*',value='',regex=True) # replace the words after a colon\n",
    "context_list = context[context.columns[0]].values.tolist()\n",
    "print(context_list[0:100])\n",
    "print(\"\\n\"\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to use POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this calls the function\n",
    "def word2features(sent, i): \n",
    "    word = sent[i][0] #takes each token\n",
    "    postag = sent[i][1] #this is the Part of Speach Tager\n",
    "    \n",
    "     #this tells if each token is in the ontology or not \n",
    "    if word in materials_list: \n",
    "        in_materials = True \n",
    "    else:\n",
    "        in_materials = False\n",
    "    \n",
    "#     if word in taxon_list: \n",
    "#         in_taxon = True \n",
    "#     else:\n",
    "#         in_taxon = False\n",
    "    \n",
    "    if word in animal_list: \n",
    "        in_animal = True \n",
    "    else:\n",
    "        in_animal = False\n",
    "  \n",
    "    if word in periods_list: \n",
    "        in_periods = True \n",
    "    else:\n",
    "        in_periods = False\n",
    "\n",
    "    if word in context_list: \n",
    "        in_context = True \n",
    "    else:\n",
    "        in_context = False\n",
    "    \n",
    "    #time to give each token some information     \n",
    "    features = { # these are all default. \n",
    "        'bias': 1.0, # bias is just 1. \n",
    "        'word.lower()': word.lower(), # tells if the token is lower case \n",
    "        'word[-3:]': word[-3:], # takes the last four letters - the suffix\n",
    "        'Word.in_materials': in_materials, #is the token in the material ontology\n",
    "#         'Word.in_taxon': in_taxon, #is the token in the material ontology\n",
    "#         'Word.in_animal': in_animal, #is the token in the periods ontology \n",
    "        'Word.in_periods': in_periods, #is the token in the periods ontology\n",
    "        'Word.in_context': in_context, #is the token in the evidence ontology\n",
    "        'word.isupper()': word.isupper(), # tells if the whole token is uppercase \n",
    "        'word.istitle()': word.istitle(), # tells if the token is capital first letter\n",
    "        'postag': postag,  # what is its label - Part-Of-Speech Tagger\n",
    "        'postag[:2]': postag[:2],  #Takes the first three letters of the tag\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0: #if the token is not at the start of a sentence\n",
    "        word1 = sent[i-1][0] # works out details of the token before - this is to understand the context \n",
    "        postag1 = sent[i-1][1] #what is the postag of the word before\n",
    "        wordbefore = (sent[i-1][0]+ ' ' +sent[i][0]).lower #this is the token and the token before\n",
    "        #if this word and word before is in the ontology then \n",
    "        if wordbefore in materials_list: \n",
    "            wordbefore_in_materials = True \n",
    "        else:\n",
    "            wordbefore_in_materials = False\n",
    "\n",
    "#         if wordbefore in taxon_list: \n",
    "#             wordbefore_in_taxon = True \n",
    "#         else:\n",
    "#             wordbefore_in_taxon = False\n",
    "\n",
    "        if wordbefore in animal_list: \n",
    "            wordbefore_in_animal = True \n",
    "            print(word)\n",
    "        else:\n",
    "            wordbefore_in_animal = False\n",
    "\n",
    "        if wordbefore in periods_list: \n",
    "            wordbefore_in_periods = True \n",
    "        else:\n",
    "            wordbefore_in_periods = False\n",
    "\n",
    "        if wordbefore in context_list: \n",
    "            wordbefore_in_context = True \n",
    "        else:\n",
    "            wordbefore_in_context = False\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(), # tells if the token is lower case\n",
    "            '-1:word.istitle()': word1.istitle(), # tells if the token is capital first letter\n",
    "            '-1:word.isdigit()': word1.isdigit(), # tells if the toekn is only numbers\n",
    "            '-1:word.isupper()': word1.isupper(),# tells if the whole token is uppercase\n",
    "            'wordbefore_in_materials': wordbefore_in_materials,\n",
    "#             'wordbefore_in_taxon': wordbefore_in_taxon,\n",
    "#             'wordbefore_in_animal': wordbefore_in_animal,\n",
    "            'wordbefore_in_periods': wordbefore_in_periods,\n",
    "            'wordbefore_in_context': wordbefore_in_context,\n",
    "            '-1:postag': postag1, # what was its POS tag\n",
    "            '-1:postag[:2]': postag1[:2], #what is the first three POS tag of the word before\n",
    "        })\n",
    "    \n",
    "        if i > 1: #if the token is not at the start of a sentence\n",
    "                word3 = sent[i-1][0] # works out details of the token before - this is to understand the context \n",
    "                postag3 = sent[i-1][1] #what is the postag of the word before\n",
    "                two_words_before = (sent[i-1][0]+ ' ' +sent[i-1][0]+ ' ' +sent[i][0]).lower #this is the token and the token before\n",
    "                #if this word and word before is in the ontology then \n",
    "                if two_words_before in materials_list: \n",
    "                    two_words_before_in_materials = True \n",
    "                else:\n",
    "                    two_words_before_in_materials = False\n",
    "\n",
    "#                 if two_words_before in taxon_list: \n",
    "#                     two_words_before_in_taxon = True \n",
    "#                 else:\n",
    "#                     two_words_before_in_taxon = False\n",
    "\n",
    "                if two_words_before in animal_list: \n",
    "                    two_words_before_in_animal = True \n",
    "                    print(word)\n",
    "                else:\n",
    "                    two_words_before_in_animal = False\n",
    "\n",
    "                if two_words_before in periods_list: \n",
    "                    two_words_before_in_periods = True \n",
    "                else:\n",
    "                    two_words_before_in_periods = False\n",
    "\n",
    "                if two_words_before in context_list: \n",
    "                    two_words_before_in_context = True \n",
    "                else:\n",
    "                    two_words_before_in_context = False\n",
    "                features.update({\n",
    "                    '-1:word.lower()': word1.lower(), # tells if the token is lower case\n",
    "                    '-1:word.istitle()': word1.istitle(), # tells if the token is capital first letter\n",
    "                    '-1:word.isdigit()': word1.isdigit(), # tells if the toekn is only numbers\n",
    "                    '-1:word.isupper()': word1.isupper(),# tells if the whole token is uppercase\n",
    "                    'two_words_before_in_materials': two_words_before_in_materials,\n",
    "#                     'two_words_before_in_taxon': two_words_before_in_taxon,\n",
    "#                     'two_words_before_in_animal': two_words_before_in_animal,\n",
    "                    'two_words_before_in_periods': two_words_before_in_periods,\n",
    "                    'two_words_before_in_context': two_words_before_in_context,\n",
    "                    '-2-postag': postag3, # what was its POS tag\n",
    "                    '-2:postag[:2]': postag3[:2], #what is the first three POS tag of the word before\n",
    "                })\n",
    "        else:\n",
    "            features['BOS2'] = True # if word is the beggining of sentence label it as so         \n",
    "    else:\n",
    "        features['BOS'] = True # if word is the beggining of sentence label it as so \n",
    "        \n",
    "    if i < len(sent)-1: # is the word at the end of the sentence. sme as above after\n",
    "        wordafter= (sent[i][0]+ ' ' +sent[i+1][0]).lower\n",
    "        #this tells if the token AFTER and each token combined is in the ontology or not\n",
    "        if wordafter in materials_list: \n",
    "            wordafter_in_materials = True \n",
    "        else:\n",
    "            wordafter_in_materials = False\n",
    "\n",
    "#         if wordafter in taxon_list: \n",
    "#             wordafter_in_taxon = True \n",
    "#         else:\n",
    "#             wordafter_in_taxon = False\n",
    "\n",
    "        if wordafter in animal_list: \n",
    "            wordafter_in_animal = True \n",
    "        else:\n",
    "            wordafter_in_animal = False\n",
    "\n",
    "        if wordafter in periods_list: \n",
    "            wordafter_in_periods = True \n",
    "        else:\n",
    "            wordafter_in_periods = False\n",
    "\n",
    "        if wordafter in context_list: \n",
    "            wordafter_in_context = True \n",
    "        else:\n",
    "            wordafter_in_context = False\n",
    "        word2 = sent[i+1][0]  \n",
    "        postag2 = sent[i+1][1] \n",
    "        features.update({\n",
    "            'wordafter_in_materials': wordafter_in_materials,\n",
    "#             'wordafter_in_taxon': wordafter_in_taxon,\n",
    "#             'wordafter_in_animal': wordafter_in_animal,\n",
    "            'wordafter_in_periods': wordafter_in_periods,\n",
    "            'wordafter_in_context': wordafter_in_context,\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "        })\n",
    "        \n",
    "        if i < len(sent)-2: #if the token is not at the start of a sentence\n",
    "                word4 = sent[i-1][0] # works out details of the token before - this is to understand the context \n",
    "                postag4 = sent[i-1][1] #what is the postag of the word before\n",
    "                two_words_after = (sent[i][0]+ ' ' +sent[i+1][0]+ ' ' +sent[i+1][0]).lower#this is the token and the token before\n",
    "                #if this word and word before is in the ontology then \n",
    "                if two_words_after in materials_list: \n",
    "                    two_words_after_in_materials = True \n",
    "                else:\n",
    "                    two_words_after_in_materials = False\n",
    "\n",
    "#                 if two_words_after in taxon_list: \n",
    "#                     two_words_after_in_taxon = True \n",
    "#                 else:\n",
    "#                     two_words_after_in_taxon = False\n",
    "\n",
    "                if two_words_after in animal_list: \n",
    "                    two_words_after_in_animal = True \n",
    "                    print(word)\n",
    "                else:\n",
    "                    two_words_after_in_animal = False\n",
    "\n",
    "                if two_words_after in periods_list: \n",
    "                    two_words_after_in_periods = True \n",
    "                else:\n",
    "                   two_words_after_in_periods = False\n",
    "\n",
    "                if two_words_after in context_list: \n",
    "                    two_words_after_in_context = True \n",
    "                else:\n",
    "                    two_words_after_in_context = False\n",
    "                features.update({\n",
    "                    '-1:word.lower()': word4.lower(), # tells if the token is lower case\n",
    "                    '-1:word.istitle()': word4.istitle(), # tells if the token is capital first letter\n",
    "                    '-1:word.isdigit()': word4.isdigit(), # tells if the toekn is only numbers\n",
    "                    '-1:word.isupper()': word4.isupper(),# tells if the whole token is uppercase\n",
    "                    'two_words_after_in_materials': two_words_after_in_materials,\n",
    "#                     'two_words_after_in_taxon': two_words_after_in_taxon,\n",
    "#                     'two_words_after_in_animal': two_words_after_in_animal,\n",
    "                    'two_words_after_in_periods': two_words_after_in_periods,\n",
    "                    'two_words_after_in_context': two_words_after_in_context,\n",
    "                    '-2-postag': postag4, # what was its POS tag\n",
    "                    '-2:postag[:2]': postag4[:2], #what is the first three POS tag of the word before\n",
    "                })\n",
    "        else:\n",
    "            features['EOS2'] = True # if word is the beggining of sentence label it as so       \n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        features['EOS'] = True # if word is the end of sentence label it as so         \n",
    "   \n",
    "\n",
    "    if i < len(sent)-1 and i > 0: # is the word at the end of the sentence. sme as above after\n",
    "            word3 = sent[i+1][0]  \n",
    "            postag3 = sent[i+1][1] \n",
    "            wordsorround = (sent[i-1][0]+ ' ' +sent[i][0]+ ' ' +sent[i+1][0]).lower\n",
    "            if wordsorround in materials_list: \n",
    "                wordsorround_in_materials = True \n",
    "            else:\n",
    "                wordsorround_in_materials = False\n",
    "\n",
    "#             if wordsorround in taxon_list: \n",
    "#                 wordsorround_in_taxon = True \n",
    "#             else:\n",
    "#                 wordsorround_in_taxon = False\n",
    "\n",
    "            if wordsorround in animal_list: \n",
    "                wordsorround_in_animal = True \n",
    "            else:\n",
    "                wordsorround_in_animal = False\n",
    "\n",
    "            if wordsorround in periods_list: \n",
    "                wordsorround_in_periods = True \n",
    "            else:\n",
    "                wordsorround_in_periods = False\n",
    "\n",
    "            if wordsorround in context_list: \n",
    "                wordsorround_in_context = True \n",
    "            else:\n",
    "                wordsorround_in_context = False\n",
    "            features.update({\n",
    "                'wordsorround_in_materials': wordsorround_in_materials,\n",
    "#                 'wordsorround_in_taxon': wordsorround_in_taxon,\n",
    "#                 'wordsorround_in_animal': wordsorround_in_animal,\n",
    "                'wordsorround_in_periods': wordsorround_in_periods,\n",
    "                'wordsorround_in_context': wordsorround_in_context,\n",
    "            })\n",
    "            if i < len(sent)-2 and i > 1: # is the word at the end of the sentence. sme as above after\n",
    "                word5 = sent[i+1][0]  \n",
    "                postag5 = sent[i+1][1] \n",
    "                twowordsorround = (sent[i-2][0]+ ' ' +sent[i-1][0]+ ' ' +sent[i][0]+ ' ' +sent[i+1][0]+ ' ' +sent[i+2][0]).lower\n",
    "                if twowordsorround in materials_list: \n",
    "                    twowordsorround_in_materials = True \n",
    "                else:\n",
    "                    twowordsorround_in_materials = False\n",
    "\n",
    "#                 if twowordsorround in taxon_list: \n",
    "#                     twowordsorround_in_taxon = True \n",
    "#                 else:\n",
    "#                     twowordsorround_in_taxon = False\n",
    "\n",
    "                if twowordsorround in animal_list: \n",
    "                    twowordsorround_in_animal = True \n",
    "                else:\n",
    "                    twowordsorround_in_animal = False\n",
    "\n",
    "                if twowordsorround in periods_list: \n",
    "                    twowordsorround_in_periods = True \n",
    "                else:\n",
    "                    twowordsorround_in_periods = False\n",
    "\n",
    "                if twowordsorround in context_list: \n",
    "                    twowordsorround_in_context = True \n",
    "                else:\n",
    "                    twowordsorround_in_context = False\n",
    "                features.update({\n",
    "                    'twowordsorround_in_materials': twowordsorround_in_materials,\n",
    "#                     'twowordsorround_in_taxon': twowordsorround_in_taxon,\n",
    "#                     'twowordsorround_in_animal': twowordsorround_in_animal,\n",
    "                    'twowordsorround_in_periods': twowordsorround_in_periods,\n",
    "                    'twowordsorround_in_context': twowordsorround_in_context,                   \n",
    "                })\n",
    "            else:\n",
    "                    features['OWS'] = True # if word is the end of sentence label it as so \n",
    "    else:\n",
    "            features['OWS'] = True # if word is the end of sentence label it as so \n",
    "            \n",
    "    return features # output these details\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))] #output for each word\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent] #output for each token\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent] #output for ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sent2features[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'introduction',\n",
       "   'word[-3:]': 'ION',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   'BOS': True,\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '7',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   '-1:word.lower()': '.',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   '-2-postag': '.',\n",
       "   '-2:postag[:2]': '.',\n",
       "   'OWS': True},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '7',\n",
       "   'word[-3:]': '7',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'introduction',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': True,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'BOS2': True,\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '1.1',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'OWS': True},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '1.1',\n",
       "   'word[-3:]': '1.1',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '7',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'project',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NN',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'project',\n",
       "   'word[-3:]': 'ect',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '1.1',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'background',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'background',\n",
       "   'word[-3:]': 'und',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'project',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NN',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '7',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '7',\n",
       "   'word[-3:]': '7',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'background',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '1.2',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '1.2',\n",
       "   'word[-3:]': '1.2',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '7',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'site',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'site',\n",
       "   'word[-3:]': 'ite',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '1.2',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'location',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'location',\n",
       "   'word[-3:]': 'ion',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'site',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'and',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CC',\n",
       "   '+2:postag[:2]': 'CC',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'location',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'description',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'description',\n",
       "   'word[-3:]': 'ion',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CC',\n",
       "   '-2:postag[:2]': 'CC',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '7',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '7',\n",
       "   'word[-3:]': '7',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'description',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '1.3',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '1.3',\n",
       "   'word[-3:]': '1.3',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '7',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'archaeological',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'archaeological',\n",
       "   'word[-3:]': 'cal',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '1.3',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'background',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNP',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'background',\n",
       "   'word[-3:]': 'und',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNP',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'archaeological',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '7',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '7',\n",
       "   'word[-3:]': '7',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'background',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNP',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNP',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '1.4',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '1.4',\n",
       "   'word[-3:]': '1.4',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '7',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'methodologies',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNS',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'methodologies',\n",
       "   'word[-3:]': 'ies',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '1.4',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '9',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '9',\n",
       "   'word[-3:]': '9',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'methodologies',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNS',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '1.5',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '1.5',\n",
       "   'word[-3:]': '1.5',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '9',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'professional',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'JJ',\n",
       "   '+2:postag[:2]': 'JJ',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'professional',\n",
       "   'word[-3:]': 'nal',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '1.5',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'standards',\n",
       "   '+2:word.istitle()': True,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNS',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'standards',\n",
       "   'word[-3:]': 'rds',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'professional',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'JJ',\n",
       "   '-2:postag[:2]': 'JJ',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '9',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '9',\n",
       "   'word[-3:]': '9',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': 'standards',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'NNS',\n",
       "   '-2:postag[:2]': 'NN',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '2',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CD',\n",
       "   '+2:postag[:2]': 'CD',\n",
       "   'two_words_after_in_materials': False,\n",
       "   'two_words_after_in_periods': False,\n",
       "   'two_words_after_in_context': False,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'twowordsorround_in_materials': False,\n",
       "   'twowordsorround_in_periods': False,\n",
       "   'twowordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '2',\n",
       "   'word[-3:]': '2',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CD',\n",
       "   'postag[:2]': 'CD',\n",
       "   'word.isdigit()': True,\n",
       "   '-1:word.lower()': '9',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '.',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': '.',\n",
       "   '+2:postag[:2]': '.',\n",
       "   'EOS2': True,\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False,\n",
       "   'OWS': True},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': '2',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CD',\n",
       "   '-1:postag[:2]': 'CD',\n",
       "   'two_words_before_in_materials': False,\n",
       "   'two_words_before_in_periods': False,\n",
       "   'two_words_before_in_context': False,\n",
       "   '-2-postag': 'CD',\n",
       "   '-2:postag[:2]': 'CD',\n",
       "   'EOS': True,\n",
       "   'OWS': True}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent2features(train_sent[0:1])[0]\n",
    "[sent2features(s) for s in train_sent[0:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to train the NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 11min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sent] # for the token train the ner on the learned set\n",
    "y_train = [sent2labels(s) for s in train_sent] # for the POS tag train the ner on the learned set\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sent] # for the token train the ner on the test set\n",
    "y_test = [sent2labels(s) for s in test_sent] # for the POS tag train the ner on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.0020339643465827964,  #was initially 0.1 each\n",
    "    c2=0.028003487848126302, # 'c1': 0.2963053968677204, 'c2': 0.004195898642365605\n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'B-CON',\n",
       " 'I-CON',\n",
       " 'B-MAT',\n",
       " 'B-ART',\n",
       " 'I-ART',\n",
       " 'I-MAT',\n",
       " 'B-SPE',\n",
       " 'I-SPE']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_) # get the list of all labels\n",
    "labels.remove('O') # remove the ones where bio is o - not got a postag\n",
    "labels # show what the labels are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to evaluate its success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7087903366157648"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the f1 score\n",
    "y_pred = crf.predict(X_test) # work out and predict what is the likely token\n",
    "metrics.flat_f1_score(y_test, y_pred, # work out what the likely postag will be, and give it a f1 score\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ART      0.750     0.517     0.612       470\n",
      "       I-ART      0.359     0.583     0.444        96\n",
      "       B-CON      0.851     0.444     0.583       399\n",
      "       I-CON      0.545     0.316     0.400        57\n",
      "       B-LOC      0.915     0.565     0.699       115\n",
      "       I-LOC      0.758     0.627     0.686        75\n",
      "       B-MAT      0.400     0.095     0.154        63\n",
      "       I-MAT      0.000     0.000     0.000        13\n",
      "       B-PER      0.924     0.839     0.880       610\n",
      "       I-PER      0.949     0.825     0.883       674\n",
      "       B-SPE      1.000     0.265     0.419        83\n",
      "       I-SPE      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.837     0.641     0.726      2655\n",
      "   macro avg      0.621     0.423     0.480      2655\n",
      "weighted avg      0.840     0.641     0.713      2655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=['B-ART', 'I-ART', 'B-CON', 'I-CON', 'B-LOC', 'I-LOC', 'B-MAT', 'I-MAT', 'B-PER', 'I-PER', 'B-SPE', 'I-SPE'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "D:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#calculate the metrics table\n",
    "# group B and I results - this isnt needed, but orders the list\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "# print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.flat_classification_report(\n",
    "   y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-ART  -> I-ART   4.950781\n",
      "I-ART  -> I-ART   4.811125\n",
      "I-PER  -> I-PER   4.231683\n",
      "B-MAT  -> I-MAT   4.148878\n",
      "B-SPE  -> I-SPE   4.075080\n",
      "I-CON  -> I-CON   3.957006\n",
      "B-CON  -> I-CON   3.947398\n",
      "I-LOC  -> I-LOC   3.667744\n",
      "B-LOC  -> I-LOC   3.555150\n",
      "B-PER  -> I-PER   3.330972\n",
      "I-MAT  -> I-MAT   2.894665\n",
      "O      -> O       2.860960\n",
      "I-SPE  -> I-SPE   2.129927\n",
      "O      -> B-PER   1.695458\n",
      "I-MAT  -> B-ART   1.284819\n",
      "O      -> B-SPE   1.263639\n",
      "B-MAT  -> B-ART   1.162508\n",
      "O      -> B-CON   1.117980\n",
      "O      -> B-MAT   0.968311\n",
      "I-MAT  -> B-CON   0.575015\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-LOC  -> B-PER   -1.682775\n",
      "B-MAT  -> I-ART   -1.754772\n",
      "B-ART  -> I-PER   -1.775023\n",
      "B-ART  -> B-CON   -1.780052\n",
      "B-CON  -> I-ART   -1.881260\n",
      "B-PER  -> B-PER   -1.915037\n",
      "B-CON  -> B-PER   -2.002334\n",
      "B-PER  -> I-ART   -2.031868\n",
      "B-LOC  -> I-PER   -2.114449\n",
      "B-ART  -> B-ART   -2.247674\n",
      "B-PER  -> I-CON   -2.298478\n",
      "I-PER  -> B-PER   -2.314461\n",
      "O      -> I-MAT   -2.317262\n",
      "B-PER  -> I-LOC   -2.493341\n",
      "B-MAT  -> I-CON   -2.731272\n",
      "I-ART  -> B-ART   -2.840072\n",
      "O      -> I-ART   -4.488998\n",
      "O      -> I-CON   -4.922743\n",
      "O      -> I-LOC   -5.614848\n",
      "O      -> I-PER   -5.698860\n"
     ]
    }
   ],
   "source": [
    "#work out which of the transitions are most likely in descending order\n",
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "#what are the 20 most likely transitions\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "#what are the 20 least likely transitions\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.548950 B-CON    word.lower():postholes\n",
      "5.262618 B-ART    word.lower():coping\n",
      "4.908019 B-PER    word[-3:]:xon\n",
      "4.824819 B-PER    word[-3:]:/05\n",
      "4.786406 O        EOS\n",
      "4.748562 B-ART    word.lower():loomweight\n",
      "4.731413 B-MAT    word.lower():ragstone\n",
      "4.653805 B-CON    word.lower():post-holes\n",
      "4.606401 I-ART    -1:word.lower():building\n",
      "4.587876 B-LOC    word.lower():leicester\n",
      "4.499557 I-PER    word.lower():centuries\n",
      "4.301774 B-PER    word.lower():post-medieval\n",
      "4.290516 B-PER    word.lower():ad1900-present\n",
      "4.097517 B-ART    word.lower():pottery\n",
      "4.090136 B-PER    +2:word.lower():os\n",
      "4.077737 B-SPE    word.lower():cattle\n",
      "4.072276 B-SPE    word.lower():barley\n",
      "4.033074 B-PER    word[-3:]:val\n",
      "4.014984 B-LOC    word[-3:]:ton\n",
      "4.012385 B-PER    word.lower():modern\n",
      "3.994716 B-CON    word.lower():firepits\n",
      "3.973232 B-CON    word.lower():barracks\n",
      "3.967981 B-MAT    word.lower():cemented\n",
      "3.909211 B-CON    word.lower():staircase\n",
      "3.808642 B-ART    word.lower():seeds\n",
      "3.794326 B-ART    word.lower():mandible\n",
      "3.753984 B-CON    word.lower():ditch\n",
      "3.710311 I-PER    -1:word.lower():unspecific\n",
      "3.682332 B-ART    word.lower():debitage\n",
      "3.676586 B-SPE    word.lower():horses\n",
      "\n",
      "Top negative:\n",
      "-2.006709 O        -1:word.lower():st\n",
      "-2.036372 O        word.lower():ragstone\n",
      "-2.064988 O        word.lower():ad\n",
      "-2.064988 O        word[-3:]:AD\n",
      "-2.085576 O        word.lower():wooden\n",
      "-2.087787 O        word.lower():england\n",
      "-2.104288 O        word.lower():basement\n",
      "-2.123804 O        word.lower():ditches\n",
      "-2.132655 O        word[-3:]:ula\n",
      "-2.200936 B-CON    -1:word.lower():large\n",
      "-2.213107 O        word[-3:]:ton\n",
      "-2.226811 O        word.lower():foundations\n",
      "-2.243882 O        word.lower():equipment\n",
      "-2.283683 O        -1:word.lower():c.\n",
      "-2.304173 B-PER    +2:word.lower():seeds\n",
      "-2.321881 O        word.lower():sherd\n",
      "-2.388050 O        word.lower():windows\n",
      "-2.388476 O        word.lower():foundation\n",
      "-2.428989 O        -1:word.lower():unstratified\n",
      "-2.450996 O        word[-3:]:eat\n",
      "-2.473193 O        word.lower():grain\n",
      "-2.475074 O        -1:word.lower():rom\n",
      "-2.487337 O        -1:word.lower():fired\n",
      "-2.488374 O        word[-3:]:ole\n",
      "-2.503592 O        word.lower():gully\n",
      "-2.682072 O        word.lower():prehistoric\n",
      "-2.738377 O        -1:word.lower():possibly\n",
      "-2.742985 O        word.lower():wares\n",
      "-2.765171 O        word[-3:]:ury\n",
      "-2.878318 O        word.lower():kent\n"
     ]
    }
   ],
   "source": [
    "#What aspects of the terms make it likely to be that tag\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "#what are the 30 most likely aspects\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "#what 30 aspects make it least likely to be that term\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dont run this takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this is to work out the best parameters for the testing. not needed yet but can increase the results by .1 \n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=50, \n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crf = rs.best_estimator_  # shows that the best params are \n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = [s.parameters['c1'] for s in rs.grid_scores_]\n",
    "_y = [s.parameters['c2'] for s in rs.grid_scores_]\n",
    "_c = [s.mean_validation_score for s in rs.grid_scores_]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 12)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C1')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
    "    min(_c), max(_c)\n",
    "))\n",
    "\n",
    "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
    "\n",
    "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
