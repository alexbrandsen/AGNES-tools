{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9e4d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439374\n",
      "{'Dutch-bio\\\\tokenised-D29580_RAP_2703_4110382.bio': 74576, 'Dutch-bio\\\\tokenised-D33460_hoofdstuk1.bio': 22409, 'Dutch-bio\\\\tokenised-D33513_07_zoologie.bio': 12518, 'Dutch-bio\\\\tokenised-D33527_GELM-STL-07_eindrapportage_ZAN_110.bio': 10828, 'Dutch-bio\\\\tokenised-D33620_Definitief_rapport_Aalst-Dorpsstraat.bio': 12310, 'Dutch-bio\\\\tokenised-D33649_08ank_rapport.bio': 2551, 'Dutch-bio\\\\tokenised-D38589_RA2217_DOVT3.bio': 49512, 'Dutch-bio\\\\tokenised-D38589_RA2217_DOVT3_bijlage_1.bio': 4938, 'Dutch-bio\\\\tokenised-D46229_ARA81_1R_Stichtse_Kant_bedrijventerrein.bio': 5337, 'Dutch-bio\\\\tokenised-D48036_RAM_202_Rijckholt_def.bio': 75982, 'Dutch-bio\\\\tokenised-D49541_A-11-0119.bio': 7960, 'Dutch-bio\\\\tokenised-D53631_06-Gk1-Griftdijk-print.bio': 74408, 'Dutch-bio\\\\tokenised-D55391_0604_DO4_rapport_definitief.bio': 30162, 'Dutch-bio\\\\tokenised-D56943_Rapport179_binnenwerk.bio': 27362, 'Dutch-bio\\\\tokenised-D59132_Rapport_205.bio': 28521}\n",
      "439374\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "line_in_txt = {}\n",
    "import os\n",
    "def countlines(directory = \"./\", lines=0, ext=\".bio\", skip_blank=False):\n",
    "    # initialize lines to 0 at the start\n",
    "    # loop through all subfolders and files on the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # loop through the files\n",
    "        for filename in files:\n",
    "            # if file does not end with ext skip it and start\n",
    "            # the loop to check the next file\n",
    "            if not filename.endswith(ext):\n",
    "                continue\n",
    "            # relative path to the file\n",
    "            file = os.path.join(root, filename)\n",
    "            # Open the file in read mode (r)\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                if skip_blank:\n",
    "                    # skip blank spaces. i.strip() captures non-blank.\n",
    "                    new_lines = len([i for i in f.readlines() if i.strip()])\n",
    "                else:\n",
    "                    # count all the lines including blank ones\n",
    "                    new_lines = len(f.readlines())\n",
    "                # add the new_lines found on the current file to the total (lines)\n",
    "                lines = lines + new_lines\n",
    "                line_in_txt[file] = new_lines\n",
    "            #print(file,\"------>\",new_lines) # only if needing to have a look inside at the individual number of lines \n",
    "    return lines\n",
    "# call the function\n",
    "print(countlines(directory=\"Dutch-bio\",ext=\".bio\", skip_blank=True)) # counts the total number of lines \n",
    "print(line_in_txt) # displays the dictionary of lines and their file\n",
    "total_lines = sum(line_in_txt.values()) # Counts the number of lines in the dictionary\n",
    "total_entries = len(line_in_txt.values()) #counts the number of entries in the dictionary to check if all documents were looked at\n",
    "print(total_lines)\n",
    "print(total_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d016b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split 351499\n",
      "train max 369074\n",
      "train min 333924\n",
      "test split 87875\n",
      "test max 92269\n",
      "test min 83481\n"
     ]
    }
   ],
   "source": [
    "split_percent = 0.8# makes it easier to define split. Just look for this\n",
    "\n",
    "train_split = round(total_lines *split_percent) #calculates the proportion of lines needed for the value wanted rounded for ease\n",
    "\n",
    "print(\"train split \"+ str(train_split))\n",
    "train_split_max = round(train_split * 1.05) # makes the max which is plus 5%\n",
    "train_split_min = round(train_split * 0.95) #makes the min which is minus 5%\n",
    "print(\"train max \"+ str(train_split_max)) #states the maximum number\n",
    "print(\"train min \"+ str(train_split_min)) #states the minimum number\n",
    "\n",
    "test_split = round(total_lines *(1-split_percent)) #calculates the proportion of lines needed for the value wanted rounded for ease\n",
    "\n",
    "print(\"test split \"+ str(test_split))\n",
    "test_split_max = round(test_split * 1.05) # makes the max which is plus 5%\n",
    "test_split_min = round(test_split * 0.95) #makes the min which is minus 5%\n",
    "print(\"test max \"+ str(test_split_max)) #states the maximum number\n",
    "print(\"test min \"+ str(test_split_min)) #states the minimum number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8656dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch-bio\\tokenised-D33649_08ank_rapport.bio too small 2551\n",
      "Dutch-bio\\tokenised-D38589_RA2217_DOVT3_bijlage_1.bio too small 4938\n",
      "Dutch-bio\\tokenised-D46229_ARA81_1R_Stichtse_Kant_bedrijventerrein.bio too small 5337\n",
      "Dutch-bio\\tokenised-D49541_A-11-0119.bio too small 7960\n",
      "Dutch-bio\\tokenised-D33527_GELM-STL-07_eindrapportage_ZAN_110.bio too small 10828\n",
      "Dutch-bio\\tokenised-D33620_Definitief_rapport_Aalst-Dorpsstraat.bio too small 12310\n",
      "Dutch-bio\\tokenised-D33513_07_zoologie.bio too small 12518\n",
      "Dutch-bio\\tokenised-D33460_hoofdstuk1.bio too small 22409\n",
      "Dutch-bio\\tokenised-D56943_Rapport179_binnenwerk.bio too small 27362\n",
      "Dutch-bio\\tokenised-D59132_Rapport_205.bio too small 28521\n",
      "Dutch-bio\\tokenised-D55391_0604_DO4_rapport_definitief.bio too small 30162\n",
      "Dutch-bio\\tokenised-D38589_RA2217_DOVT3.bio too small 49512\n",
      "Dutch-bio\\tokenised-D53631_06-Gk1-Griftdijk-print.bio too small 74408\n",
      "Dutch-bio\\tokenised-D29580_RAP_2703_4110382.bio too small 74576\n",
      "Dutch-bio\\tokenised-D48036_RAM_202_Rijckholt_def.bio too small 75982\n"
     ]
    }
   ],
   "source": [
    "#sort the dictionary to make it easier\n",
    "Sorted_line_in_txt = sorted(line_in_txt.items(), key=lambda x:x[1], reverse=False ) #this turns the sorted lines into a string but in order\n",
    "sorted_dictionary_line_in_txt = dict(Sorted_line_in_txt) #turns it back into a dictionary that is sorted    \n",
    "#print(sorted_dictionary_line_in_txt)\n",
    "for key, val in sorted_dictionary_line_in_txt.items(): # iterates through the now sorted dictionary   \n",
    "    if val < train_split_max: # if it it less than the max    #### if and ######\n",
    "        if val > train_split_min: # and more than the min\n",
    "            print(val) # print it \n",
    "        else: \n",
    "            print(key+\" too small \"+ str(val)) \n",
    "    else: \n",
    "        print(key+\"too big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21a34e33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dutch-bio\\\\tokenised-D33649_08ank_rapport.bio', 'Dutch-bio\\\\tokenised-D38589_RA2217_DOVT3_bijlage_1.bio', 'Dutch-bio\\\\tokenised-D46229_ARA81_1R_Stichtse_Kant_bedrijventerrein.bio', 'Dutch-bio\\\\tokenised-D49541_A-11-0119.bio', 'Dutch-bio\\\\tokenised-D33527_GELM-STL-07_eindrapportage_ZAN_110.bio', 'Dutch-bio\\\\tokenised-D33620_Definitief_rapport_Aalst-Dorpsstraat.bio', 'Dutch-bio\\\\tokenised-D33513_07_zoologie.bio', 'Dutch-bio\\\\tokenised-D33460_hoofdstuk1.bio', 'Dutch-bio\\\\tokenised-D56943_Rapport179_binnenwerk.bio', 'Dutch-bio\\\\tokenised-D59132_Rapport_205.bio', 'Dutch-bio\\\\tokenised-D55391_0604_DO4_rapport_definitief.bio', 'Dutch-bio\\\\tokenised-D38589_RA2217_DOVT3.bio', 'Dutch-bio\\\\tokenised-D53631_06-Gk1-Griftdijk-print.bio']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "total2 = 0\n",
    "test_selected_documents = []\n",
    "test_unselected_documents = []\n",
    "train_selected_documents = []\n",
    "train_unselected_documents = []\n",
    "success = False\n",
    "success2 = False\n",
    "\n",
    "for key, val in sorted_dictionary_line_in_txt.items(): # iterates through the now sorted dictionary   \n",
    "    if val < test_split_max: # if it it less than the max    #### if and ######\n",
    "        if val > test_split_min: # and more than the min\n",
    "            print(\"Just use this one \"+key)\n",
    "            #print(val) # print it \n",
    "        else: \n",
    "            total = total + val # add the value to the total\n",
    "\n",
    "            #print (total) # print this value to check\n",
    "            if test_split_max > total > test_split_min: #if this new value is in between the set key\n",
    "                #print(key+\" \"+str(total))\n",
    "                success = True \n",
    "                print(test_selected_documents)\n",
    "                print(test_unselected_documents)\n",
    "\n",
    "            else:\n",
    "                if  test_split_max > total:\n",
    "                    #print(key+\" too small\")\n",
    "                    test_selected_documents.append(key)\n",
    "                   \n",
    "                else:            \n",
    "                    #print(key+str(total) + \"too big: checking train documents\")\n",
    "                    test_unselected_documents.append(key)\n",
    "    else:\n",
    "            print(\"file too big\")\n",
    "\n",
    "    if not success:\n",
    "        total = 0\n",
    "        if val < train_split_max: # if it it less than the max    #### if and ######\n",
    "            if val > train_split_min: # and more than the min\n",
    "                print(\"\")\n",
    "                #print(val) # print it \n",
    "            else: \n",
    "                total2 = total2 + val # add the value to the total\n",
    "\n",
    "                #print (total) # print this value to check\n",
    "                if train_split_max > total2 > train_split_min: #if this new value is in between the set key\n",
    "                    #print(key+\" \"+str(total2))\n",
    "                    success2 = True \n",
    "                    print(train_selected_documents)\n",
    "                    print(train_unselected_documents)\n",
    "                else:\n",
    "                    if  train_split_max < total2:\n",
    "                        #print(key+str(total) + \"too big\")\n",
    "                        train_unselected_documents.append(key)\n",
    "                    else:            \n",
    "                        #print(key+\" too small\")\n",
    "                        train_selected_documents.append(key)\n",
    "        else: \n",
    "            print(key+\" too big\")\n",
    "\n",
    "if not (success or success2):\n",
    "    print (\"do it yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "310ab8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the files \n",
    "\n",
    "if success:\n",
    "    print(\")\")\n",
    "    # Open file3 in write mode\n",
    "    with open('test_docucment.txt', 'w', encoding='utf8') as outfile:\n",
    "\n",
    "        # Iterate through list\n",
    "        for names in test_selected_documents:\n",
    "\n",
    "            # Open each file in read mode\n",
    "            with open(names) as infile:\n",
    "\n",
    "                # read the data from file1 and\n",
    "                # file2 and write it in file3\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "            # Add '\\n' to enter data of file2\n",
    "            # from next line\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "    # Open file3 in write mode\n",
    "    with open('train_docucment.txt', 'w') as outfile:\n",
    "\n",
    "        # Iterate through list\n",
    "        for names in test_unselected_documents:\n",
    "\n",
    "            # Open each file in read mode\n",
    "            with open(names) as infile:\n",
    "\n",
    "                # read the data from file1 and\n",
    "                # file2 and write it in file3\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "            # Add '\\n' to enter data of file2\n",
    "            # from next line\n",
    "            outfile.write(\"\\n\")  \n",
    "            \n",
    "            \n",
    "elif success2:\n",
    "\n",
    "    # Open file3 in write mode\n",
    "    with open('train_docucment.txt', 'w', encoding='utf8') as outfile:\n",
    "\n",
    "        # Iterate through list\n",
    "        for names in train_selected_documents:\n",
    "\n",
    "            # Open each file in read mode\n",
    "            with open(names, encoding='utf8') as infile:\n",
    "\n",
    "                # read the data from file1 and\n",
    "                # file2 and write it in file3\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "                # Add '\\n' to enter data of file2\n",
    "                # from next line\n",
    "                outfile.write(\"\\n\")\n",
    "                \n",
    "    # Open file3 in write mode\n",
    "    with open('test_docucment.txt', 'w', encoding='utf8') as outfile:\n",
    "\n",
    "        # Iterate through list\n",
    "        for names in train_unselected_documents:\n",
    "\n",
    "            # Open each file in read mode\n",
    "            with open(names, encoding='utf8') as infile:\n",
    "\n",
    "                # read the data from file1 and\n",
    "                # file2 and write it in file3\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "            # Add '\\n' to enter data of file2\n",
    "            # from next line\n",
    "            outfile.write(\"\\n\") \n",
    "\n",
    "else:\n",
    "    print('you need the last cell to run first')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##### for just one file \n",
    "    if val < train_split_max: # if it it less than the max    #### if and ######\n",
    "        if val > train_split_min: # and more than the min\n",
    "            print(\"\")\n",
    "            #print(val) # print it \n",
    "        else: \n",
    "            total = total + val # add the value to the total\n",
    "            \n",
    "            #print (total) # print this value to check\n",
    "            if train_split_max > total > train_split_min: #if this new value is in between the set key\n",
    "                print(key+\" \"+str(total))\n",
    "                \n",
    "            else:\n",
    "                if  train_split_max < total:\n",
    "                    print(key+str(total) + \"too big\")\n",
    "                    unselected_documents.append(key)\n",
    "                else:            \n",
    "                    print(key+\" too small\")\n",
    "                    selected_documents.append(key)\n",
    "    else: \n",
    "        print(key+\" too big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a41c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e102b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bd491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
