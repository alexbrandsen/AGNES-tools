{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c544d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef2ca4a-25ea-46f5-bda3-7c6f97c9fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in c:\\anaconda\\envs\\trial2\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: six in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from sklearn_crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from sklearn_crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from sklearn_crfsuite) (4.64.1)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from sklearn_crfsuite) (0.9.8)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\envs\\trial2\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: nltk in c:\\anaconda\\envs\\trial2\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: importlib-metadata in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from click->nltk) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from importlib-metadata->click->nltk) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\anaconda\\envs\\trial2\\lib\\site-packages (from importlib-metadata->click->nltk) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "#install required packages\n",
    "!pip install sklearn_crfsuite\n",
    "!pip install scikit-learn \n",
    "!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cedfca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd \n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn_crfsuite\n",
    "\n",
    "#from matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from itertools\n",
    "from itertools import chain\n",
    "\n",
    "#from sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3450fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707032b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function turns the file into a list. \n",
    "def file2list(fileLocation):\n",
    "    outputList = []\n",
    "    with open(fileLocation, 'r', encoding='utf8') as myfile:\n",
    "        sentences = myfile.read().split('\\n\\n')\n",
    "        for sentence in sentences:\n",
    "                sentenceList = []\n",
    "                words = sentence.split('\\n')\n",
    "                for word in words:\n",
    "                    wordsList = []\n",
    "                    attributes = word.split(' ')\n",
    "                    for attribute in attributes:\n",
    "                        wordsList.append(attribute)\n",
    "                    sentenceList.append(wordsList)\n",
    "                outputList.append(sentenceList)\n",
    "    \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a95bfb9-29bd-4260-907c-6136def7d09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the datasets, with training documents as train, and test documents and test\n",
    "train =  file2list('txt/train.txt') \n",
    "test =  file2list('txt/test.txt') \n",
    "#remove empty lines as this breaks the code\n",
    "test.pop() \n",
    "train.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a17316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['All', 'DT', 'O'],\n",
       " ['statements', 'NNS', 'O'],\n",
       " ['and', 'CC', 'O'],\n",
       " ['opinions', 'NNS', 'O'],\n",
       " ['in', 'IN', 'O'],\n",
       " ['this', 'DT', 'O'],\n",
       " ['document', 'NN', 'O'],\n",
       " ['are', 'VBP', 'O'],\n",
       " ['offered', 'VBN', 'O'],\n",
       " ['in', 'IN', 'O'],\n",
       " ['good', 'JJ', 'O'],\n",
       " ['faith', 'NN', 'O'],\n",
       " ['.', '.', 'O']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# calculates the time to open the file\n",
    "        #train the NER on the list. there is one set of test and one of training. often 20:80 split\n",
    "train_sent = train\n",
    "test_sent = test   # tests the sent (input) of the given list as defined above\n",
    "\n",
    "train_sent[0] # displayes the first 10 rows in the bio. - each row hs the token (effectively word), followed by pos?, and the bio label\n",
    "# to identify whats below - token - label(specific label) - common derivitive of word (for posting would be post)  - then the bio label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a7162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elm', 'felt', 'alabaster', 'spruce', 'tamarac', 'aluminum', 'variscite', 'argillite', 'totternhoe clunch', 'ash', 'aluminium', 'carnelian', 'cornelian', 'plaster', 'sapphire', 'paper', 'ebony', 'garnet', 'rubber', 'coal', 'emerald', 'hazel', 'puddingstone', 'hertfordshire puddingstone', 'charcoal', 'chalk', 'hydrocarbon', 'bakelite', 'amethyst', 'amphibolite', 'larch', 'siltstone', 'mudstone', 'utahlite', 'teak', 'shale', 'ivory', 'marble', 'limestone', 'leather', 'lead', 'lava', 'faience', 'jadeite', 'tooth', 'iron', 'pottery', 'greenstone', 'gold', 'glass', 'flint', 'jet', 'silver', 'pewter', 'obsidian', 'sandstone', 'object material', 'oak', 'mineral', 'wood', 'shell', 'quartz', 'slate', 'steel', 'stone', 'terracotta', 'tin', 'granite', 'quartzite', 'fir', 'antimony', 'schist', 'birch', 'lead alloy', 'zinc', 'dolerite', 'ceramic', 'pine', 'fibreglass', 'glass fibre', 'graphite', 'jade', 'onyx', 'fiberglass', 'beech', 'textile', 'metal', 'alloy', 'bronze', 'horn', 'brass', 'bone', 'antler', 'animal', 'cement', 'chert', 'clay', 'concrete', 'copper', 'amber', 'copper alloy', 'enamel', 'earthenware']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\trial2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 3090873: expected 22 fields, saw 25\\n'\n",
      "C:\\Anaconda\\envs\\trial2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (3,10,12,16,19,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urocystis beckwithiae vánky', 'urocystis murashkinskyi (cif.) zundel', 'urocystis pulsatillae-albae vánky & tóth', 'urocystis vulpiae vánky', 'urocystis bulbinellae (p.h.b. talbot) vánky, m. lutz, r. bauer & piątek', 'biota', 'velocipedoidea', 'urocystis simplex (liro) vánky', 'urocystis skirgielloae piątek', 'urocystis curculiginis a.r. patil, t.m. patil & m.s. patil', 'urocystis clintoniae (kom.) uljan. ex govorova', 'urocystis paridis (unger) thüm.', 'urocystis tranzscheliana (lavrov) zundel', 'urocystis lithophragmatis garrett', 'urocystis puccinelliae l. guo & h.c. zhang', 'urocystis chorizandrae cunningt., r.g. shivas & vánky', 'urocystis circaeasteri vánky', 'urocystis aurea vánky', 'urocystis yunnanensis l. guo', 'callichilella', 'urocystis callianthemi domashova', 'urocystis pseudoanemones denchev, kakish. & y. harada', 'urocystis macrospora (desm.) liro', 'urocystis beijingensis l. guo', 'urocystis filipendulae (tul. & c. tul.) j. schröt.', 'urocystis reinhardii m. piepenbr., quintana & garret', 'urocystis alstroemeriae vánky & c. vánky', 'urocystis thaxteri vánky', 'urocystis scilloides denchev & kakish.', 'urocystis antipolitana magnus', 'urocystis helanensis l. guo', 'urocystis achnatheri l. guo', 'urocystis qinghaiensis l. guo', 'urocystis antarctica (speg.) vánky', 'urocystis trautvetteriae vánky', 'urocystis sichuanensis l. guo', 'urocystis rytzii (massenot) j. müll.', 'urocystis phlei (lavrov) ignat.', 'chrysina limbata (rothschild & jordan, 1894)', 'urocystis phlei-alpini terrier', 'urocystis nevodovskyi schwarzman', 'urocystis paraquilegiae petr.', 'urocystis secalis-silvestris (uljan.) schwarzman', 'urocystis picbaueri součk.-tomk.', 'urocystis rechingeri petr.', 'urocystis agropyri (preuss) a.a. fisch. waldh.', 'urocystis beckmanniae i.e. brezhnev', 'urocystis aquilegiae (cif.) schwarzman', 'urocystis elymi (cif.) schwarzman', 'urocystis cortusae (liro) schwarzman', 'urocystis hordeicola (lavrov) schwarzman', 'urocystis fischeri körn.', 'urocystis multispora y.c. wang', 'urocystis mayorii (cif.) uljan.', 'neoloxops', 'urocystis camassiae vánky', 'urocystis narcissi (gonz. frag.) vánky', 'urocystis tothii vánky', 'mesotropiscus', 'urocystis poae-palustris vánky', 'urocystis permagna roiv.', 'urocystis bulbocodii vánky', 'urocystis oxygraphidis vasyag.', 'urocystis melicae (lagerh. & liro) zundel', 'urocystis agrostidis (lavrov) zundel', 'urocystis andina (speg.) zundel', 'urocystis alaskana zundel', 'urocystis atragenes (liro) zundel', 'urocystis arrhenatheri (kuprev.) săvul.', 'urocystis avenae-elatioris (kochman) zundel', 'urocystis atropidis (lavrov) zundel', 'urocystis castellana (gonz. frag.) zundel', 'urocystis avenastri (massenot) nannf.', 'chrysina lecontei (horn, 1882)', 'urocystis nivalis (liro) zundel', 'urocystis muscaridis (niessl) moesz', 'urocystis littoralis (lagerh.) zundel', 'urocystis komarovii (lavrov) zundel', 'urocystis irregularis (g. winter) săvul.', 'urocystis hordei (cif.) zundel', 'urocystis gladiolicola ainsw.', 'urocystis gageae kalymb.', 'urocystis ferrarisiana (cif.) zundel', 'urocystis eriospermi (syd.) zundel', 'urocystis eranthidis (pass.) ainsw. & sampson', 'urocystis delphinii golovin', 'urocystis dactylidina (lavrov) zundel', 'urocystis tianschanica golovin', 'urocystis trientalis (berk. & broome) b. lindeb.', 'urocystis syncocca (l.a. kirchn.) b. lindeb.', 'chrysina laniventris (sturm, 1843)', 'urocystis tessellata (liro) zundel', 'urocystis schizocaulon (ces.) zundel', 'urocystis subnuda (liro) zundel', 'urocystis rigida (liro) zundel', 'urocystis rodgersiae (miyabe ex s. ito) zundel', 'atomoscelis', 'urocystis ranunculi-bullati (cif.) zundel', 'urocystis ranunculi-lanuginosi (dc.) zundel', 'urocystis ranunculi (lib.) moesz']\n",
      "\n",
      "\n",
      "\n",
      "['ヒメシンサンカクガイ', 'australmuschel australian', 'brooch clam', 'große flussperlmuschel', 'riesen-flussperlmuschel', \"spengler's freshwater mussel\", 'giant european freshwater pearl mussel', 'louisiana pearlshell', 'western pearlshell', 'westliche flussperlmuschel', 'western freshwater pearl mussel', 'alabama pearlshell', 'eastern pearlshell', 'flussperlmuschel', 'scottish pearl mussel', 'freshwater pearl mussel', 'ウスモシオ', 'スダレモシオ', 'モシオガイ', 'ワタゾコモシオ', 'サガミモシオガイ', 'zwinkokkel', 'フミガイ', 'ハタウネフミガイ', 'rudder cardita', 'トマヤガイ', 'ニクイロトマヤガイ', 'rectangular false cockle', 'クロフトマヤガイ', 'large-ribbed cardita', 'クロマルフミガイ', 'vénéricarde boréale', 'new england cyclocardia', 'north pacific bobtail squid', 'north pacific bobtail squid', 'bouzuika', 'globito del pacífico boreal', 'sépiole du pacifique boréal', 'globito de tasmania', 'sarura', 'southern bobtail squid', 'sépiole du tasmanie', 'mimika bobtail', 'mimika bobtail squid', 'mò-shì-sì-pán-êr-wu-zéi', 'globito mimika', 'sépiole mimika', 'ミミイカ', 'bèi-ruì-shì-sì-pán-êr-wu-zéi', 'double-ear bobtail', 'globito colibri', 'humming-bird bobtail squid', 'leung yee jai', 'niyori-mimi-ika', 'sépiole colibri', 'ニヨリミミイカ', 'brenner’s bobtail', 'burenā-mimika', 'rì-bĕn-àn-êr-wu-zéi', 'チョウチンイカ', 'kleine sepiette', 'linsen-sepiette', 'cappuccetto', 'globito pequeño', 'lentil bobtail', 'lentil bobtail squid', 'seppiola minore', 'sépiole bobie', 'σουπίτσα', 'σουπίτσα φακή', 'elegante sepiette', 'elegant bobtail', 'elegant bobtail squid', 'sepieta elegante', 'sépiole élégante', 'συμμετρική σουπίτσα', 'obskure sepiette', 'sepiette', 'mysterious bobtail squid', 'ramshorn', 'sepieta misteriosa', 'seppiola misteriosa', 'sépiole mystérieuse', 'σουπίτσα αίνιγμα', 'große sepiette', 'cappuccetto', 'common bobtail', 'common bobtail squid', 'greater cuttlefish', 'langwerpige dwerginktvis', 'sepieta común', 'seppiola comune', 'supion', 'sépiole', 'sépiole commune', 'σουπίτσα', 'atlantic bobtail', 'atlantic bobtail squid', 'atlantic cuttlefish', 'atlantik-stummelschwanzsepi']\n",
      "\n",
      "\n",
      "\n",
      "['la tène c', 'la tène d', 'la tène d1', 'la tène d2', 'silla kingdom', 'koguryo kingdom', 'paekche kingdom', 'sasanian', 'unified silla dynasty', 'kushano-sasanian', 'western turks', 'alchon', 'indo-greek', 'hun', 'greco-bactrian', 'epi-palaeolithic', 'hephthalite', 'tularosa', 'afsharid dynasty', 'old assyrian', 'late babylonian', 'neo-babylonian dynasty', 'dilmun', 'punuk', 'old bering sea culture', 'inca', 'late bronze age/early iron age', 'romano-british', 'early medieval', 'pagan', 'sonso', 'gaudo', 'early archaic', 'middle archaic', 'punic', 'kushan', 'bmac', 'rimac', 'calima', 'san agustin', 'tumaco', 'tumaco-la tolita', 'early quimbaya', 'quimbaya', 'yotoco', 'zenu', 'early tolima', 'san agustin regional classic', 'tolima', 'tairona', 'muisca', 'narino', 'late quimbaya', 'serrania de san jacinto', 'tairona period', 'cauca', 'proto-corinthian', 'early minoan', 'early minoan i', 'early minoan ii', 'early minoan iia', 'early minoan iib', 'early minoan iii', 'middle minoan', 'middle minoan i', 'middle minoan ia', 'middle minoan ib', 'middle minoan ii', 'middle minoan iia', 'middle minoan iib', 'middle minoan iii', 'middle minoan iiia', 'middle minoan iiib', 'late minoan', 'late minoan i', 'late minoan ia', 'late minoan ib', 'late minoan ii', 'late minoan iii', 'late minoan iiia', 'late minoan iiia1', 'late minoan iiia2', 'late minoan iiib', 'late minoan iiib1', 'late minoan iiib2', 'late minoan iiic', 'sub-minoan', 'early cycladic', 'grotta-pelos culture', 'keros-syros culture', 'phylakopi i culture', 'middle cycladic', 'late cycladic', 'early cypriot', 'early cypriot i', 'early cypriot ii', 'early cypriot iii', 'middle cypriot', 'late cypriot', 'late cypriot ib']\n",
      "\n",
      "\n",
      "\n",
      "['post-hole', 'post-hole', 'post-hole', 'post-hole', 'post-hole', 'building', 'building', 'building', 'building', 'building', 'building', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'corn-drying oven', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'ditch overall', 'drain', 'drain', 'drain', 'drain', 'drain', 'drain', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'four-post structure', 'hearth', 'hearth', 'hearth', 'hearth', 'hearth', 'hearth', 'kiln', 'kiln', 'kiln', 'kiln', 'kiln', 'kiln', 'oven', 'oven', 'oven', 'oven', 'oven', 'oven', 'road', 'road', 'road', 'road', 'road', 'road', 'structure', 'structure', 'structure', 'structure', 'structure', 'structure', 'well', 'well', 'well', 'well', 'well', 'well', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'animal disturbance', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'ard mark', 'bank', 'bank', 'bank', 'bank', 'bank']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\trial2\\lib\\site-packages\\ipykernel_launcher.py:35: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "#time to load the ontologies \n",
    "\n",
    "#Material ontology\n",
    "materials = pd.read_csv(r'ontologies\\Materials.csv') #open the file\n",
    "materials[materials.columns[2]]= materials[materials.columns[2]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "materials_list = materials[materials.columns[2]].values.tolist() #turns the items into a list\n",
    "print(materials_list) # outputs the list of terms to see what sort of data it contains\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "#Taxon ontology\n",
    "taxon = pd.read_csv(r'ontologies\\Taxon.tsv', sep=\"\\t\", error_bad_lines=False) #open the file\n",
    "taxon[taxon.columns[8]]= taxon[taxon.columns[8]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "taxon_list = taxon[taxon.columns[8]].values.tolist() #turns the items into a list\n",
    "print(taxon_list[0:100]) # outputs the list of terms to see what sort of data it contains\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "#Animal ontology\n",
    "animal = pd.read_csv(r'ontologies\\VernacularName.tsv', sep=\"\\t\") #open the file\n",
    "animal[animal.columns[2]]= animal[animal.columns[2]].str.lower() #takes the second column (the one with the entities) and makes it all lower case\n",
    "animal_list = animal[animal.columns[2]].values.tolist() #turns the items into a list\n",
    "print(animal_list[0:100]) # outputs the list of terms to see what sort of data it contains\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "\n",
    "#Periods ontology - for notes see above\n",
    "periods = pd.read_csv(r'ontologies\\Periods.csv')\n",
    "periods[periods.columns[1]]= periods[periods.columns[1]].str.lower()\n",
    "periods_list = periods[periods.columns[1]].values.tolist()\n",
    "print(periods_list[0:100])\n",
    "print(\"\\n\"\"\\n\")\n",
    "\n",
    "\n",
    "#Context ontology - for notes see material \n",
    "context = pd.read_csv(r'ontologies\\context.csv')\n",
    "context[context.columns[0]]= context[context.columns[0]].str.lower().str.replace('*','').str.replace('<','').str.replace('>','') #replace all other symbols\n",
    "context[context.columns[0]]= context[context.columns[0]].replace(to_replace =':.*',value='',regex=True) # replace the words after a colon\n",
    "context_list = context[context.columns[0]].values.tolist()\n",
    "print(context_list[0:100])\n",
    "print(\"\\n\"\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a22fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to use POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3576042-0d57-41e4-a704-2ef79460f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this calls the function\n",
    "def word2features(sent, i): \n",
    "    word = sent[i][0] #takes each token\n",
    "    postag = sent[i][1] #this is the Part of Speach Tager\n",
    "    \n",
    "    \n",
    "\n",
    "    #this tells if each token is in the ontology or not \n",
    "    if word in materials_list: \n",
    "        in_materials = True \n",
    "    else:\n",
    "        in_materials = False\n",
    "    \n",
    "    if word in taxon_list: \n",
    "        in_taxon = True \n",
    "    else:\n",
    "        in_taxon = False\n",
    "    \n",
    "    if word in animal_list: \n",
    "        in_animal = True \n",
    "    else:\n",
    "        in_animal = False\n",
    "  \n",
    "    if word in periods_list: \n",
    "        in_periods = True \n",
    "    else:\n",
    "        in_periods = False\n",
    "\n",
    "    if word in context_list: \n",
    "        in_context = True \n",
    "    else:\n",
    "        in_context = False\n",
    "    \n",
    "    #time to give each token some information     \n",
    "    features = { # these are all default. \n",
    "        'bias': 1.0, # bias is just 1. \n",
    "        'word.lower()': word.lower(), # tells if the token is lower case \n",
    "        'word[-3:]': word[-3:], # takes the last four letters - the suffix\n",
    "        'Word.in_materials': in_materials, #is the token in the material ontology\n",
    "        'Word.in_taxon': in_taxon, #is the token in the material ontology\n",
    "        'Word.in_animal': in_animal, #is the token in the periods ontology \n",
    "        'Word.in_periods': in_periods, #is the token in the periods ontology\n",
    "        'Word.in_context': in_context, #is the token in the evidence ontology\n",
    "        'word.isupper()': word.isupper(), # tells if the whole token is uppercase \n",
    "        'word.istitle()': word.istitle(), # tells if the token is capital first letter\n",
    "        'postag': postag,  # what is its label - Part-Of-Speech Tagger\n",
    "        'postag[:2]': postag[:2],  #Takes the first three letters of the tag\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0: #if the token is not at the start of a sentence\n",
    "        word1 = sent[i-1][0] # works out details of the token before - this is to understand the context \n",
    "        postag1 = sent[i-1][1] #what is the postag of the word before\n",
    "        wordbefore = sent[i-1][0]+ ' ' +sent[i][0] #this is the token and the token before\n",
    "        #if this word and word before is in the ontology then \n",
    "        if wordbefore in materials_list: \n",
    "            wordbefore_in_materials = True \n",
    "        else:\n",
    "            wordbefore_in_materials = False\n",
    "\n",
    "        if wordbefore in taxon_list: \n",
    "            wordbefore_in_taxon = True \n",
    "        else:\n",
    "            wordbefore_in_taxon = False\n",
    "\n",
    "#         if wordbefore in animal_list: \n",
    "#             wordbefore_in_animal = True \n",
    "#         else:\n",
    "#             wordbefore_in_animal = False\n",
    "\n",
    "        if wordbefore in periods_list: \n",
    "            wordbefore_in_periods = True \n",
    "        else:\n",
    "            wordbefore_in_periods = False\n",
    "\n",
    "        if wordbefore in context_list: \n",
    "            wordbefore_in_context = True \n",
    "        else:\n",
    "            wordbefore_in_context = False\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(), # tells if the token is lower case\n",
    "            '-1:word.istitle()': word1.istitle(), # tells if the token is capital first letter\n",
    "            '-1:word.isdigit()': word1.isdigit(), # tells if the toekn is only numbers\n",
    "            '-1:word.isupper()': word1.isupper(),# tells if the whole token is uppercase\n",
    "            'wordbefore_in_materials': wordbefore_in_materials,\n",
    "            'wordbefore_in_taxon': wordbefore_in_taxon,\n",
    "#             'wordbefore_in_animal': wordbefore_in_animal,\n",
    "            'wordbefore_in_periods': wordbefore_in_periods,\n",
    "            'wordbefore_in_context': wordbefore_in_context,\n",
    "            '-1:postag': postag1, # what was its POS tag\n",
    "            '-1:postag[:2]': postag1[:2], #what is the first three POS tag of the word before\n",
    "            'word_before': sent[i-1][0]+ ' ' +sent[i][0] # what was the token and the token before it\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True # if word is the beggining of sentence label it as so \n",
    "        \n",
    "    if i < len(sent)-1: # is the word at the end of the sentence. sme as above after\n",
    "        wordafter= sent[i][0]+ ' ' +sent[i+1][0]\n",
    "        #this tells if the token AFTER and each token combined is in the ontology or not\n",
    "        if wordafter in materials_list: \n",
    "            wordafter_in_materials = True \n",
    "        else:\n",
    "            wordafter_in_materials = False\n",
    "\n",
    "        if wordafter in taxon_list: \n",
    "            wordafter_in_taxon = True \n",
    "        else:\n",
    "            wordafter_in_taxon = False\n",
    "\n",
    "#         if wordafter in animal_list: \n",
    "#             wordafter_in_animal = True \n",
    "#         else:\n",
    "#             wordafter_in_animal = False\n",
    "\n",
    "        if wordafter in periods_list: \n",
    "            wordafter_in_periods = True \n",
    "        else:\n",
    "            wordafter_in_periods = False\n",
    "\n",
    "        if wordafter in context_list: \n",
    "            wordafter_in_context = True \n",
    "        else:\n",
    "            wordafter_in_context = False\n",
    "        word2 = sent[i+1][0]  \n",
    "        postag2 = sent[i+1][1] \n",
    "        features.update({\n",
    "            'wordafter_in_materials': wordafter_in_materials,\n",
    "            'wordafter_in_taxon': wordafter_in_taxon,\n",
    "#             'wordafter_in_animal': wordafter_in_animal,\n",
    "            'wordafter_in_periods': wordafter_in_periods,\n",
    "            'wordafter_in_context': wordafter_in_context,\n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "            'Word_after': sent[i][0]+ ' ' +sent[i+1][0]\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # if word is the end of sentence label it as so         \n",
    "   \n",
    "\n",
    "    if i < len(sent)-1 and i > 0: # is the word at the end of the sentence. sme as above after\n",
    "#             word3 = sent[i+1][0]  \n",
    "#             postag3 = sent[i+1][1] \n",
    "            wordsorround = sent[i-1][0]+ ' ' +sent[i][0]+ ' ' +sent[i+1][0]\n",
    "            if wordsorround in materials_list: \n",
    "                wordsorround_in_materials = True \n",
    "            else:\n",
    "                wordsorround_in_materials = False\n",
    "\n",
    "            if wordsorround in taxon_list: \n",
    "                wordsorround_in_taxon = True \n",
    "            else:\n",
    "                wordsorround_in_taxon = False\n",
    "\n",
    "            if wordsorround in animal_list: \n",
    "                wordsorround_in_animal = True \n",
    "            else:\n",
    "                wordsorround_in_animal = False\n",
    "\n",
    "            if wordsorround in periods_list: \n",
    "                wordsorround_in_periods = True \n",
    "            else:\n",
    "                wordsorround_in_periods = False\n",
    "\n",
    "            if wordsorround in context_list: \n",
    "                wordsorround_in_context = True \n",
    "            else:\n",
    "                wordsorround_in_context = False\n",
    "                features.update({\n",
    "            'wordsorround_in_materials': wordsorround_in_materials,\n",
    "            'wordsorround_in_taxon': wordsorround_in_taxon,\n",
    "            'wordsorround_in_animal': wordsorround_in_animal,\n",
    "            'wordsorround_in_periods': wordsorround_in_periods,\n",
    "            'wordsorround_in_context': wordsorround_in_context,\n",
    "            })\n",
    "    else:\n",
    "            features['OWS'] = True # if word is the end of sentence label it as so \n",
    "            \n",
    "    return features # output these details\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))] #output for each word\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent] #output for each token\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent] #output for ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75babd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sent2features[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35321811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word.lower()': 'all',\n",
       "   'word[-3:]': 'All',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'word.isdigit()': False,\n",
       "   'BOS': True,\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'statements',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNS',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'Word_after': 'All statements',\n",
       "   'OWS': True},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'statements',\n",
       "   'word[-3:]': 'nts',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'all',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   'word_before': 'All statements',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'and',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'CC',\n",
       "   '+2:postag[:2]': 'CC',\n",
       "   'Word_after': 'statements and',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'and',\n",
       "   'word[-3:]': 'and',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'statements',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'word_before': 'statements and',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'opinions',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NNS',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'Word_after': 'and opinions',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'opinions',\n",
       "   'word[-3:]': 'ons',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'NNS',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'and',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   'word_before': 'and opinions',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'in',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'IN',\n",
       "   '+2:postag[:2]': 'IN',\n",
       "   'Word_after': 'opinions in',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'opinions',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NNS',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'word_before': 'opinions in',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'this',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'DT',\n",
       "   '+2:postag[:2]': 'DT',\n",
       "   'Word_after': 'in this',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'this',\n",
       "   'word[-3:]': 'his',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': True,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'DT',\n",
       "   'postag[:2]': 'DT',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   'word_before': 'in this',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'document',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NN',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'Word_after': 'this document',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'document',\n",
       "   'word[-3:]': 'ent',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'this',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'DT',\n",
       "   '-1:postag[:2]': 'DT',\n",
       "   'word_before': 'this document',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'are',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'VBP',\n",
       "   '+2:postag[:2]': 'VB',\n",
       "   'Word_after': 'document are',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'are',\n",
       "   'word[-3:]': 'are',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'VBP',\n",
       "   'postag[:2]': 'VB',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'document',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'word_before': 'document are',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'offered',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'VBN',\n",
       "   '+2:postag[:2]': 'VB',\n",
       "   'Word_after': 'are offered',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'offered',\n",
       "   'word[-3:]': 'red',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'VBN',\n",
       "   'postag[:2]': 'VB',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'are',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'VBP',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   'word_before': 'are offered',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'in',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'IN',\n",
       "   '+2:postag[:2]': 'IN',\n",
       "   'Word_after': 'offered in',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'in',\n",
       "   'word[-3:]': 'in',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'IN',\n",
       "   'postag[:2]': 'IN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'offered',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'VBN',\n",
       "   '-1:postag[:2]': 'VB',\n",
       "   'word_before': 'offered in',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'good',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'JJ',\n",
       "   '+2:postag[:2]': 'JJ',\n",
       "   'Word_after': 'in good',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'good',\n",
       "   'word[-3:]': 'ood',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'in',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'IN',\n",
       "   '-1:postag[:2]': 'IN',\n",
       "   'word_before': 'in good',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': 'faith',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': 'NN',\n",
       "   '+2:postag[:2]': 'NN',\n",
       "   'Word_after': 'good faith',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'faith',\n",
       "   'word[-3:]': 'ith',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': 'NN',\n",
       "   'postag[:2]': 'NN',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'good',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   'word_before': 'good faith',\n",
       "   'wordafter_in_materials': False,\n",
       "   'wordafter_in_taxon': False,\n",
       "   'wordafter_in_periods': False,\n",
       "   'wordafter_in_context': False,\n",
       "   '+2:word.lower()': '.',\n",
       "   '+2:word.istitle()': False,\n",
       "   '+2:word.isupper()': False,\n",
       "   '+2:postag': '.',\n",
       "   '+2:postag[:2]': '.',\n",
       "   'Word_after': 'faith .',\n",
       "   'wordsorround_in_materials': False,\n",
       "   'wordsorround_in_taxon': False,\n",
       "   'wordsorround_in_animal': False,\n",
       "   'wordsorround_in_periods': False,\n",
       "   'wordsorround_in_context': False},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'Word.in_materials': False,\n",
       "   'Word.in_taxon': False,\n",
       "   'Word.in_animal': False,\n",
       "   'Word.in_periods': False,\n",
       "   'Word.in_context': False,\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'postag': '.',\n",
       "   'postag[:2]': '.',\n",
       "   'word.isdigit()': False,\n",
       "   '-1:word.lower()': 'faith',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isdigit()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   'wordbefore_in_materials': False,\n",
       "   'wordbefore_in_taxon': False,\n",
       "   'wordbefore_in_periods': False,\n",
       "   'wordbefore_in_context': False,\n",
       "   '-1:postag': 'NN',\n",
       "   '-1:postag[:2]': 'NN',\n",
       "   'word_before': 'faith .',\n",
       "   'EOS': True,\n",
       "   'OWS': True}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent2features(train_sent[0:1])[0]\n",
    "[sent2features(s) for s in train_sent[0:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29e6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to train the NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1310e2-573f-4064-a10a-4084644572fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sent] # for the token train the ner on the learned set\n",
    "y_train = [sent2labels(s) for s in train_sent] # for the POS tag train the ner on the learned set\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sent] # for the token train the ner on the test set\n",
    "y_test = [sent2labels(s) for s in test_sent] # for the POS tag train the ner on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f3875-dddf-4263-9b23-d84d4bccda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.0020339643465827964,  #was initially 0.1 each\n",
    "    c2=0.028003487848126302, # 'c1': 0.2963053968677204, 'c2': 0.004195898642365605\n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_) # get the list of all labels\n",
    "labels.remove('O') # remove the ones where bio is o - not got a postag\n",
    "labels # show what the labels are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to evaluate its success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94749648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the f1 score\n",
    "y_pred = crf.predict(X_test) # work out and predict what is the likely token\n",
    "metrics.flat_f1_score(y_test, y_pred, # work out what the likely postag will be, and give it a f1 score\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the metrics table\n",
    "# group B and I results - this isnt needed, but orders the list\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "# print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.flat_classification_report(\n",
    "   y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2525f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work out which of the transitions are most likely in descending order\n",
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "#what are the 20 most likely transitions\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "#what are the 20 least likely transitions\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df645362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What aspects of the terms make it likely to be that tag\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "#what are the 30 most likely aspects\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "#what 30 aspects make it least likely to be that term\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dont run this takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81220ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this is to work out the best parameters for the testing. not needed yet but can increase the results by .1 \n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=50, \n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af52ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crf = rs.best_estimator_  # shows that the best params are \n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = [s.parameters['c1'] for s in rs.grid_scores_]\n",
    "_y = [s.parameters['c2'] for s in rs.grid_scores_]\n",
    "_c = [s.mean_validation_score for s in rs.grid_scores_]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 12)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C1')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
    "    min(_c), max(_c)\n",
    "))\n",
    "\n",
    "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
    "\n",
    "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8f133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bbf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf10de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
